---
title: "p8105_hw5_ob2305"
author: "Olya Besedina"
data: "11/04/2019"
output: github_document
---
  
```{r setup, include = FALSE}
library(tidyverse)
library(rvest)
library(viridis)

knitr::opts_chunk$set(
 	echo = TRUE,
 	warning = FALSE,
 	fig.width = 8, 
   fig.height = 6,
   out.width = "90%"
 )

options(
   ggplot2.continuous.colour = "viridis",
   ggplot2.continuous.fill = "viridis"
 )

 scale_colour_discrete = scale_colour_viridis_d
 scale_fill_discrete = scale_fill_viridis_d

 theme_set(theme_minimal() + theme(legend.position = "bottom"))
 
 set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```

# Problem 1

Count missing values in the df

```{r}
skimr::skim(iris_with_missing)
```

```{r, problem 1}
iris_with_missing = iris_with_missing %>% janitor::clean_names()

# function for num and char
my_function = function(x) {
  
  if(is.numeric(x)) {
    replace_na(x, mean(x, na.rm = TRUE))
  } else if(is.character(x)) {
    replace_na(x, "virginica")
  }
}
new_iris = map_df(iris_with_missing,my_function)

# check missing values in mapped data frame
sum_na = sum(is.na(new_iris))
names = distinct(new_iris,species)

# in line 
# The `r new_iris` data frame has `r sum_na` missing values. In character variables missing values were replaced withthe mean value of that variable and in character variable they were replaced with "virginica". Character value in the new data frame has three distinct values `r names`.
```



# Problem 2

* Read in data for each subject 
```{r, load the data}
# Read the files

read_plus <- function(x) {
    read_csv(x) %>% 
        mutate(filename = x)
}

trial =
    list.files(path = "./data/", 
               pattern = "*.csv",
               full.names = TRUE)

trial_df = map_df(trial, read_plus)
```

* Tidy the result

```{r, tidy results}
trial_tidy =
  trial_df %>%
  pivot_longer(
     -filename,
    names_to = "week",
    names_prefix = "week_",
    values_to = "value"
  ) %>% 
  mutate(
    filename = str_replace(filename, "./data//", ""),
    filename = str_replace(filename, ".csv", "")
  ) %>%  
  separate(filename, into = c("arm", "subject_id"), sep = "\\_")
 
trial_nest = 
  nest(trial_tidy, data = week:value) %>% 
  head()
```

* Spaghetti plot 

```{r, spaghetti plot}
trial_tidy %>% 
  ggplot(aes(x = week, y = value, color = subject_id, group = subject_id)) +
  geom_line() +
  facet_grid(~arm)+
  labs(
    title = "Change of values over 8 weeks for each participant"
  )
```

The plot above depicts change of values over the 8 weeks of trial for each participant in control and experimental arms. It can be seen from the plot that participants in experimental arm had an upward trend of values, in contrast to participants in the control arm.


# Problem 3

```{r, function}
set.seed(1)

sim_regression = function(beta0 = 2, beta1 = 0) {
  
  data = tibble(
    x = rnorm(30, mean = 0, sd = 1),
    y = beta0 + beta1 * x + rnorm(30, 0, sqrt(50))
  )
  
  ls_fit = lm(y ~ x, data = data) %>% 
    broom::tidy()
}

```

Generate 10000 datasets from the model

```{r, initial simulation}
set.seed(1)

output_results = rerun(10000, sim_regression()) %>% 
  bind_rows() %>% 
  janitor::clean_names() %>% 
  filter(term == "x") %>% 
  select(estimate, p_value) 
```

Simulation for beta 1:6

```{r,simulations for 6 betas}
sim_results = 
  tibble(
  beta = c(1:6)) %>% 
  mutate(
    output_list = map(.x = beta, ~rerun(10000, sim_regression(beta1 = .x))),
    output_df = map(output_list, bind_rows)
  ) %>% 
  select(-output_list) %>% 
  unnest(output_df) %>% 
  janitor::clean_names() %>% 
  filter(term == "x") %>% 
  select(beta, estimate, p_value) 
```



```{r, significant result}
sim_results_1 =
  sim_results %>% 
  group_by(beta) %>% 
  count(p_value <0.05) %>% 
  janitor::clean_names() %>% 
  select(
    p_val_sig = p_value_0_05,
    p_val_count = n) %>% 
  mutate(
     prop = p_val_count / sum(p_val_count)) %>% 
  filter(p_val_sig == "TRUE")
```

## Plots

Beta1 represends the effect size. Increase in effect size, while keeping everything constant (alpha and sample size), will cause increase in power. There is a positive association between effect size and power. This idea is supported by the plot below.

```{r, ggplot power}
sim_results_1 %>% 
  ggplot(aes(x = beta, y = prop)) +
  geom_point() +
  labs(
    x = "True value",
    y = "Power of the test" 
  )
```

Make a plot showing the average estimate of β1 on the y axis and the true value of β1 on the x axis. 

```{r, average of all estimates}
all_estimates = 
  sim_results %>% 
  group_by(beta) %>% 
  mutate(
    ave_estimate = mean(estimate)
    ) %>%
  select(beta, ave_estimate) %>% 
  distinct(beta, ave_estimate)

```

Make a second plot (or overlay on the first) the average estimate of β̂1 only in samples for which the null was rejected on the y axis and the true value of β1 on the x axis. 

```{r, significant est}
significant_estimates = 
  sim_results %>%
  filter(p_value <= 0.05) %>% 
  group_by(beta) %>%
  mutate(
    ave_sig_estimate = mean(estimate)
    ) %>%
  select(beta, ave_sig_estimate) %>% 
  distinct(beta, ave_sig_estimate) 
```


```{r, ggplot}
merged_estimates = 
  inner_join(all_estimates, significant_estimates, by = "beta") %>% 
  ggplot(aes(x = beta)) +
  geom_line(aes(y = ave_estimate, color = "blue")) +
  geom_line(aes(y = ave_sig_estimate, color = "yellow")) +
    labs(
    x = "True value of Beta1",
    y = "Average value of estimates" 
  )
```

Blue line on the graph represends the average of 10,000 samples with n = 30 for each beta1. These values correspond to the true values of the beta1. Yellow line represends the average value of each beta1 for which the null hypothesis was rejected (H_0: beta1 = 1:6). As it is seen from the plot, yellow line approaches blue when effect size increases (given everything else stays constant).  

As effect size increases, so does the power of the test. Yellow line approaches true value as effect size goes increases, because it is easier to detect effect size that is large.  


